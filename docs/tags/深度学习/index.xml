<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>深度学习 on Liuyating&#39;s Blog</title>
    <link>https://yatingliu2019.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 深度学习 on Liuyating&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <copyright>© 2025, lyt.so</copyright>
    <lastBuildDate>Tue, 26 Dec 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://yatingliu2019.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Clipcap学习笔记</title>
      <link>https://yatingliu2019.github.io/post/clipcap/</link>
      <pubDate>Tue, 26 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://yatingliu2019.github.io/post/clipcap/</guid>
      <description>&lt;h1 id=&#34;一配置学习&#34;&gt;一、配置学习&lt;/h1&gt;&#xA;&lt;p&gt;新建虚拟环境&lt;/p&gt;&#xA;&lt;p&gt;必须要有python的版本，否则pip之类的都用不了&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda create -n clipcap python&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;3.8&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;启动环境&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda activate clipcap&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;二运行github文件&#34;&gt;二、运行github文件&lt;/h1&gt;&#xA;&lt;p&gt;参考&lt;a href=&#34;https://github.com/yangjianxin1/ClipCap-Chinese/tree/master&#34;&gt;Github链接&lt;/a&gt;，下载zip文件，然后上传到MobaXterm，参考&lt;a href=&#34;http://t.csdnimg.cn/kkTzg&#34;&gt;MoaXterm博文&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;改变路径&lt;code&gt;cd &amp;lt;路径&amp;gt;&lt;/code&gt;，激活环境&lt;code&gt;conda activate clipcap&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;运行第一条命令&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;，等待&lt;/p&gt;&#xA;&lt;p&gt;运行&lt;code&gt;python process_flickr.py&lt;/code&gt;，这时候有错误提示，显示缺少&lt;strong&gt;ViT-B-32.pt&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;所以，&lt;a href=&#34;https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt&#34;&gt;下载ViT-B-32.pt&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;再次运行&lt;code&gt;python process_flickr.py&lt;/code&gt;，发现还少东西，dataset没有数据集flickr30k&lt;/p&gt;&#xA;&lt;p&gt;flickr30k&lt;a href=&#34;https://shannon.cs.illinois.edu/DenotationGraph/&#34;&gt;下载官网&lt;/a&gt;，填好表格，会给你的邮箱发送下载链接。上传flickr30k-images.tar和flickr30k.tar.gz。&lt;/p&gt;&#xA;&lt;p&gt;解压flickr30k文件&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tar -xvf flickr30k-images.tar&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;运行&lt;code&gt;bash scripts/train_finetune_gpt2.sh&lt;/code&gt;，会报错，原因在于pre_model/gpt2的文件夹里面少pytorch_model.bin文件&#xA;PS:pytorch_model.bin是PyTorch模型的二进制文件，包含了训练好的模型权重参数。少GPT2的模型权重参数，当然没法继续。下载，上传到文件夹。再次运行。此时就可以成功训练了。&lt;/p&gt;&#xA;&lt;h1 id=&#34;三clipcap代码阅读&#34;&gt;三、clipcap代码阅读&lt;/h1&gt;&#xA;&lt;p&gt;训练训练MLP+GPT2 tuning实在是太慢了&amp;hellip;趁这段时间分析一下代码，重点看一下train.py和predict.py&lt;/p&gt;&#xA;&lt;h2 id=&#34;关于导入python的库和模块&#34;&gt;关于导入python的库和模块&lt;/h2&gt;&#xA;&lt;p&gt;clipcap是pytorch框架下的，然后从pytorch中导入处理数据的类：Dataset和DataLoader，以及用来可视化训练过程的Tensorboard。&lt;/p&gt;&#xA;&lt;p&gt;关于Bert模型的配置和分词器（token）是从Huggingface的transformer库中导入的。&lt;/p&gt;&#xA;&lt;p&gt;&amp;rsquo; tqdm &amp;lsquo;库用来显示进度条，&amp;rsquo; loguru &amp;lsquo;库中的&amp;rsquo; logger &amp;lsquo;用来日志记录，&amp;rsquo; argparse &amp;lsquo;模块用来解析命令，&amp;rsquo; os &amp;lsquo;模块用来与计算机操作系统交互，&amp;rsquo; join &amp;lsquo;函数用来连接文件路径，&amp;rsquo; functional &amp;lsquo;模块包含不可学习参数的函数，如激活函数和损失函数。&lt;/p&gt;&#xA;&lt;h2 id=&#34;导入模块&#34;&gt;导入模块&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;from enum import Enum&lt;/code&gt;: 导入 Python 的 Enum 类，用于创建枚举类型。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup, BertModel, BertConfig, GPT2Config&lt;/code&gt;: 导入 Hugging Face 的 Transformers 库中的相关类和函数，包括 GPT-2 模型和 tokenizer，AdamW 优化器，学习率调度器等。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
